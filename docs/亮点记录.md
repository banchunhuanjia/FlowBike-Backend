**1.亮点一：基于 TCP 的自定义应用层协议设计与实现**
- 问题背景：
  “在面试中，你可以说：‘为了解决 TCP 协议的粘包和半包问题，保证消息的完整性和边界，我们设计并实现了一个自定义的应用层协议。’”
- 技术方案：
  “我们采用的是一种经典的‘包头-包体’ (Header-Body) 协议。包头是一个固定长度（例如8字节）的结构，其中包含了最关键的‘包体长度’字段和一个‘消息类型ID’字段。”
- 实现细节
   “在服务器的网络层 (NetworkInterface)，我们实现了一个基于状态机 (State Machine) 的消息分帧器 (Message Framer)。它有两个核心状态：‘读取包头’和‘读取包体’。只有当接收缓冲区的数据满足当前状态所需的大小时，才会进行解析和状态转移。这个机制确保了我们能从连续的 TCP 字节流中，准确无误地还原出一条条独立的应用层消息。”
- 带来的好处：
   “这个设计，使得我们的上层业务逻辑（DispatchMsgService, EventHandler）可以完全不用关心底层网络细节。它们收到的，永远是一个个完整的、可以直接处理的数据包，实现了网络层和业务层的完美解耦。”

---
**2.亮点二：网络层中引入tcpconnection这一链接管理类**
通过引入一个 RAII 风格的 TcpConnection 类并结合 std::unique_ptr，我们将复杂的、手动的、易出错的网络连接资源管理，转化为了一个简洁、自动、由 C++ 语言保证其安全性的对象生命周期管理问题，极大地提升了网络层的代码质量。

---
**3.亮点三：基于 Libevent 实现的线程安全的信号处理与服务器优雅关闭**
- 问题背景
  安全地释放所有资源后再退出会面临
  - 标准库和第三方库非线程安全，会死锁
  - 需要实现可靠的跨线程通信，因为信号可被任何线程捕获，但是关闭指令在特定的线程
- 解决方案
  - 创建信号事件 
  使用 evsignal_new() 为 SIGINT 和 SIGTERM 等关键信号创建了对应的“信号事件”对象
  - 注册到事件循环 
  通过 evsignal_add()，我们将这些信号事件注册到 libevent 的核心事件循环 (event_base) 中
  - 定义安全的回调 
  为这些信号事件绑定了一个回调函数，保证会在运行 event_base_dispatch() 的那个线程（也就是我们的网络线程）中被同步地调用
  - 在回调中执行关闭逻辑 
  在这个线程安全的回调函数中，我们再安全地调用 event_base_loopbreak()
- 一句话总结
  为了实现服务器的优雅关闭，我们没有使用存在线程安全隐患的传统POSIX信号处理，而是利用libevent的evsignal，将外部信号转化为libevent内部事件，保证所有关闭逻辑都在libevnet自身网络线程中安全执行，不仅解决了跨线程调用，也是我们的架构更符合libevent同意事件源的设计哲学。而且，采用这种 libevent 统一事件源的方案，还顺便解决了一个我们在开发初期遇到的、非常棘手的关机死锁 (Shutdown Deadlock) 问题。
- 案发现场
  - 基于sigaction的方案:
  在main函数中注册全局的信号处理器，Ctrl+C发生时从主线程直接调用networkinterface的stop方法请求libevent循环退出，出现了程序运行不到打印退出日志的位置
  - GDB调试结果:
  GDB的多线程调试时，跨线程调用libevent的loopbreak不能保证唤醒一个正阻塞在epoll_wait内核调用中的网络线程。所以网络线程就一直退出不了，主线程的jion就一直在等，出现了死锁
  - 问题根源:
  信号处理时异步非线程安全的上下文，libevent的evsignal通过self-pipe trick的内部实现将危险的异步信号变成一个安全的，在libevent自身线程中同步处理的I/O事件。经过重构之后loopbreak的调用就发生在正确线程的上下文中，死锁就没了

---
**4.亮点四：高并发IM服务器核心架构重构与稳定性优化**
- 问题
  - （回包时）Reactor模型的业务线程和网络线程交互发生了segfault
- 解决方案
  - GDB调试与Core Dump分析定位到根本原因是Use-After-Free:业务线程仍持有野指针进行写操作
  - 重构 iEvent 事件基类，移除了危险的 bufferevent* 指针，改为传递 Socket FD（文件描述符）。设计了“FD 接力”机制：请求事件携带 FD -> 业务处理 -> 响应事件继承 FD -> 网络层通过 FD 查找活跃连接。彻底消除了多线程下的野指针风险。
  - 实现了一个基于 mutex + queue 的异步回包机制。业务线程只负责生产数据，通过 Timer 机制由 IO 主线程统一消费并发送，遵循 "One Loop One Thread" 原则，避免了多线程竞争底层 Buffer
- 一句话总结
  - 针对 Reactor 模型下的多线程并发问题，重构了核心事件分发机制与构建系统，解决了 Use-After-Free 导致的崩溃与循环依赖问题

---
**5.亮点五：高并发性能瓶颈优化**
- 问题
  - 频繁建立和断开tcp连接耗时巨大，无法支撑高QPS
- 解决方案
  - 使用连接池，预先创建连接，利用shared_ptr的自定义删除器实现"回收代替销毁"
- 一句话总结
  - 池化技术实现资源复用，以空间换时间

---
**6.亮点六：DAO模式**
- 问题
  - SQL语句散落在业务中，难以维护替换
  - SQL先查后插在高并发下导致主键冲突
- 解决方案
  - 将SQL封装在独立层，业务只调用接口
  - 使用INSERT ... ON DUPLICATE KEY UPDATE将逻辑下沉
- 一句话总结
  - 分层架构实现高内聚低耦合
  - 利用数据原子性解决应用层并发冲突

---
**7.亮点七：CAS乐观锁**
- 问题
  - 并发抢锁，两台手机同时扫一个码，都显示开锁成功但是只变一次数据库状态
- 解决方案
  - 使用CAS乐观锁，用UPDATE ... WHERE status = 0的原子性，将检查和修改合并
- 一句话总结
  - 不加昂贵的互斥锁，利用数据库特性解决并发

---
**8.亮点八：开启事务，完成一致性**
- 问题
  - 用户充值”或“结束骑行扣费”涉及多个步骤（例如：1.扣减用户余额 2.增加订单流水 3.更新车辆状态）。如果中间某一步失败，会导致数据不一致
- 解决方案
  - 利用 MySQL 的事务机制 (ACID)。在 DAO 层封装了 beginTransaction, commit, rollback 接口。 利用 C++ 的 RAII 机制封装 TransactionGuard 类：构造时自动开启事务。析构时，如果业务逻辑没有显式 Commit，则自动 Rollback。
- 一句话总结
  - 通过 RAII 机制封装数据库事务，确保了复杂业务逻辑下的数据原子性，杜绝了异常崩溃导致的脏数据残留
  
---
**9.亮点九：无状态架构**
- 问题
  - 现在mysql很慢，我们需要redis
  - 但直接引入redis缓存会出现缓存不一致的问题
- 解决方案
  - mysql存储资产信息，redis存储登陆状态（token->手机号）
  - 这样数据无交集就解决了一致性问题，同时redis的使用可以提高之前用mysql查询身份是否合法的性能
  - 而且，token的引入实现了服务器的无状态话，解决了下次使用不同服务器登录无法登录的问题，与此同时还解决了身份的伪造
- 一句话总结
  - 使用分布式会话解决了安全问题，实现了分布式支持和高性能鉴权

---
**10.亮点十：全链路性能调优与瓶颈定位**
- 问题
  - 项目初期 QPS 仅为 60，严重低于预期。需要定位系统瓶颈是在网络层、业务逻辑层还是存储层。
- 解决方案
  - 使用 benchmark 工具压测，结合 htop 监控。发现 MySQL CPU 占用率达 500%，而 Server CPU 占用低，初步判定瓶颈在数据库写入
  - 为了验证 C++ Server 本身的吞吐极限，我编写了 Mock 代码屏蔽数据库层。结果 QPS 飙升至 2000+，从而从逻辑上证明了 Reactor 网络模型和线程池设计没有性能缺陷，确立了“数据库 IO 是最大短板”的结论。
  - 调整 MySQL innodb_flush_log_at_trx_commit 策略，缓解磁盘 IO 压力（QPS 提升至 600）。
  - 引入 Redis 缓存高频写入（验证码/Token），利用内存操作替代磁盘 IO（QPS 最终突破 3500）。
- 一句话总结
  - 通过 Mock 隔离和系统监控（htop），精准定位到了 MySQL 写入瓶颈，并通过架构升级将系统吞吐量提升了 58 倍。

---
**11.亮点十一：高性能日志分级策略与零开销观测**
- 问题
  - 压测初期，发现日志输出严重拖慢了 QPS。传统的同步日志会在业务线程中进行磁盘 I/O，尤其是在高频业务路径（如包解析、Token校验）打印 INFO 日志，导致严重的性能抖动
- 解决方案
  - 制定了明确的日志规范。控制面（启动/配置/低频交互）保留 INFO 级别，高频数据面（如 handle_read, handle_request）全部降级为 DEBUG
  - 在压测及生产配置中，将全局日志级别设为 WARN
  - 在核心业务链路中保留了错误路径的 ERROR 日志，确保在保持高性能的同时，不丢失关键故障现场。
- 一句话总结
  - 通过精细化的日志分级策略，在生产环境下实现了‘零 I/O 开销’运行，同时保留了开发环境的调试能力，有效解决了高并发下的日志阻塞问题。

---
**12.亮点十二：基于 ThreadLocal 的无锁资源管理**
- 问题
  - 在高并发多线程环境下，多个 Worker 线程竞争同一个 Redis 连接实例需要频繁加互斥锁，导致严重的上下文切换和锁竞争开销
- 解决方案
  - 引入 thread_local 机制管理 Redis 连接上下文 (hiredis context)。 每个工作线程在启动时初始化属于自己的 Redis 连接副本，并在线程生命周期内独享该连接。彻底消除了多线程访问 Redis 时的锁竞争（Lock-free），实现了连接资源的线程隔离
- 一句话总结
  - 利用 ThreadLocal 实现资源的线程隔离，以少量的内存空间换取了完全无锁的高并发执行效率